{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofcGsUUlrJ10",
        "outputId": "4a4c4b2a-b75a-4ae4-c70c-ef891f21f5a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-utils in /usr/local/lib/python3.8/dist-packages (3.4.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "FjCZmo0wV4dK",
        "outputId": "a61a04c2-6865-4c8e-bf7d-179610c8147a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-utils in /usr/local/lib/python3.8/dist-packages (3.4.5)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-601e64a81040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvis_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install python-utils\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from os import path\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "import time\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_red_and_yellow(img, Threshold=0.01):\n",
        "    \"\"\"\n",
        "    detect red and yellow\n",
        "    :param img:\n",
        "    :param Threshold:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    desired_dim = (30, 90)  # width, height\n",
        "    img = cv2.resize(np.array(img), desired_dim, interpolation=cv2.INTER_LINEAR)\n",
        "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # lower mask (0-10)\n",
        "    l_red = np.array([0, 70, 50])\n",
        "    u_red = np.array([10, 255, 255])\n",
        "    mask0 = cv2.inRange(img_hsv, lower_red, upper_red)\n",
        "\n",
        "    # upper mask (170-180)\n",
        "    l_red1 = np.array([170, 70, 50])\n",
        "    u_red1 = np.array([180, 255, 255])\n",
        "    mask1 = cv2.inRange(img_hsv, lower_red1, upper_red1)\n",
        "\n",
        "    # defining the Range of yellow color\n",
        "    l_yellow = np.array([21, 39, 64])\n",
        "    u_yellow = np.array([40, 255, 255])\n",
        "    mask2 = cv2.inRange(img_hsv, lower_yellow, upper_yellow)\n",
        "\n",
        "    # red pixels' mask\n",
        "    mask = mask0 + mask1 + mask2\n",
        "\n",
        "    # Compare the percentage of red values\n",
        "    rate = np.count_nonzero(mask) / (desired_dim[0] * desired_dim[1])\n",
        "\n",
        "    if rate > Threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "ICcf5UbRV6Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "metadata": {
        "id": "FN1UBVhxWCDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_traffic_lights_object(image, boxes, scores, classes, max_boxes_to_draw=20, min_score_thresh=0.5,\n",
        "                               traffic_ligth_label=10):\n",
        "    im_width, im_height = image.size\n",
        "    stop_flag = False\n",
        "    for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
        "        if scores[i] > min_score_thresh and classes[i] == traffic_ligth_label:\n",
        "            ymin, xmin, ymax, xmax = tuple(boxes[i].tolist())\n",
        "            (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
        "                                          ymin * im_height, ymax * im_height)\n",
        "            crop_img = image.crop((left, top, right, bottom))\n",
        "\n",
        "            if detect_red_and_yellow(crop_img):\n",
        "                stop_flag = True\n",
        "\n",
        "    return stop_flag\n"
      ],
      "metadata": {
        "id": "_g1rc09mWHxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_origin_image(image_np, boxes, classes, scores, category_index):\n",
        "    # Size of the output images.\n",
        "    IMAGE_SIZE = (12, 8)\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        np.squeeze(boxes),\n",
        "        np.squeeze(classes).astype(np.int32),\n",
        "        np.squeeze(scores),\n",
        "        category_index,\n",
        "        min_score_thresh=.5,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=3)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)\n",
        "\n",
        "    # save augmented images into hard drive\n",
        "    # plt.savefig( 'output_images/ouput_' + str(idx) +'.png')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "PpEReWPoWIfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_traffic_lights(PATH_TO_TEST_IMAGES_DIR, MODEL_NAME, Num_images, plot_flag=False):\n",
        "    \"\"\"\n",
        "    Detect traffic lights and draw bounding boxes around the traffic lights\n",
        "    :param PATH_TO_TEST_IMAGES_DIR: testing image directory\n",
        "    :param MODEL_NAME: name of the model used in the task\n",
        "    :return: commands: True: go, False: stop\n",
        "    \"\"\"\n",
        "\n",
        "    # --------test images------\n",
        "    TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, 'img_{}.jpg'.format(i)) for i in range(1, Num_images + 1)]\n",
        "\n",
        "    commands = []\n",
        "\n",
        "    # What model to download\n",
        "    MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "    DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "    # Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "    PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "    # List of the strings that is used to add correct label for each box.\n",
        "    PATH_TO_LABELS = 'mscoco_label_map.pbtxt'\n",
        "\n",
        "    # number of classes for COCO dataset\n",
        "    NUM_CLASSES = 90\n",
        "\n",
        "    # --------Download model----------\n",
        "    if path.isdir(MODEL_NAME) is False:\n",
        "        opener = urllib.request.URLopener()\n",
        "        opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "        tar_file = tarfile.open(MODEL_FILE)\n",
        "        for file in tar_file.getmembers():\n",
        "            file_name = os.path.basename(file.name)\n",
        "            if 'frozen_inference_graph.pb' in file_name:\n",
        "                tar_file.extract(file, os.getcwd())\n",
        "\n",
        "    # --------Load a (frozen) Tensorflow model into memory\n",
        "    detection_graph = tf.Graph()\n",
        "    with detection_graph.as_default():\n",
        "        od_graph_def = tf.GraphDef()\n",
        "        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "            serialized_graph = fid.read()\n",
        "            od_graph_def.ParseFromString(serialized_graph)\n",
        "            tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "    # ---------Loading label map\n",
        "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "    categories = label_map_util.convert_label_map_to_categories(label_map,\n",
        "                                                                max_num_classes=NUM_CLASSES,\n",
        "                                                                use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "    with detection_graph.as_default():\n",
        "        with tf.Session(graph=detection_graph) as sess:\n",
        "            # Definite input and output Tensors for detection_graph\n",
        "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "            # Each box represents a part of the image where a particular object was detected.\n",
        "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "            # Each score represent how level of confidence for each of the objects.\n",
        "            # Score is shown on the result image, together with the class label.\n",
        "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "            for image_path in TEST_IMAGE_PATHS:\n",
        "                image = Image.open(image_path)\n",
        "\n",
        "                # the array based representation of the image will be used later in order to prepare the\n",
        "                # result image with boxes and labels on it.\n",
        "                image_np = load_image_into_numpy_array(image)\n",
        "                # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "                # Actual detection.\n",
        "                (boxes, scores, classes, num) = sess.run(\n",
        "                    [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "                    feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "                stop_flag = read_traffic_lights_object(image, np.squeeze(boxes), np.squeeze(scores),\n",
        "                                                       np.squeeze(classes).astype(np.int32))\n",
        "                if stop_flag:\n",
        "                    # print('{}: stop'.format(image_path))  # red or yellow\n",
        "                    commands.append(False)\n",
        "                    cv2.putText(image_np, 'Stop', (15, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1)\n",
        "                else:\n",
        "                    # print('{}: go'.format(image_path))\n",
        "                    commands.append(True)\n",
        "                    cv2.putText(image_np, 'Go', (15, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)\n",
        "\n",
        "                # Visualization of the results of a detection.\n",
        "                if plot_flag:\n",
        "                    plot_origin_image(image_np, boxes, classes, scores, category_index)\n",
        "\n",
        "    return commands"
      ],
      "metadata": {
        "id": "HKkpqJCgWLeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Specify number of images to detect\n",
        "    Num_images = 5\n",
        "\n",
        "    # Specify test directory path\n",
        "    PATH_TO_TEST_IMAGES_DIR = './test_images'\n",
        "\n",
        "    # Specify downloaded model name\n",
        "    # MODEL_NAME ='ssd_mobilenet_v1_coco_11_06_2017'    # for faster detection but low accuracy\n",
        "    MODEL_NAME = 'faster_rcnn_resnet101_coco_11_06_2017'  # for improved accuracy\n",
        "\n",
        "    commands = detect_traffic_lights(PATH_TO_TEST_IMAGES_DIR, MODEL_NAME, Num_images, plot_flag=True)\n",
        "    print(commands)  # commands to print action type, for 'Go' this will return True and for 'Stop' this will return False"
      ],
      "metadata": {
        "id": "oLkYIILLWS7z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}